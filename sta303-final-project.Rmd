---
title: "Report title"
subtitle: "Subtitle that indicates findings"
author: "Report prepared for MINGAR by UofTears"
date: 2022-04-07
lang: "en"
output:
  pdf_document:
    template: report.tex
    toc: true
    toc_depth: 2
titlepage: true
titlepage-color: "002554"
titlepage-text-color: "FFFFFF"
titlepage-rule-color: "FFFFFF"
titlepage-rule-height: 2
---

```{r load_packages, message = FALSE, echo=FALSE}
library(tidyverse)
library(lme4)
library(rvest)
library(polite)
library(lmtest)
library(kableExtra)

# this should suppress all code and messages
knitr::opts_chunk$set(include=TRUE)
```

```{r load_data, echo=FALSE, warning=FALSE, message=FALSE}
# read in the data (this will only work once you've set up the data!)
cust_sleep_complete <- readRDS("data/cust_sleep_complete.Rds")

cust_dev_info <- readRDS("data/cust_dev_info.Rds")
cust_dev_info <- cust_dev_info %>%
  mutate(is_new = ifelse(cust_dev_info$line == "Advance" | cust_dev_info$line == "Active", 1, 0))
```

```{r performance_model, echo=FALSE, warning=FALSE, message=FALSE}
device_performance_model_fixed <- lm(flags ~ duration*emoji_modifier,
                                       data=cust_sleep_complete)
device_performance_model_mixed <- lmer(flags ~ duration*emoji_modifier+(1|age),
                                       data=cust_sleep_complete)
```

# General comments (you can delete this section)

_Before making any changes, knit this Rmd to PDF and change the name of the PDf to something like 'original-instructions.pdf', or whatever you like (it is just for your reference).. Then you can delete this section and if you want to check what it said, just open the other PDF. You don't HAVE to use this particular template, but you DO need to write you report in RMarkdown and include a cover page._

_The cover page must be a single stand alone page and have:_

*	_A title and subtitle (that indicate your findings)_
* _"Report prepared for MINGAR by" your company name_
*	_Date (assessment submission date is fine)_

_You can change the colour of this cover to any colour you would like by replacing 6C3082 in the YAML above (`titlepage-color:`) to another hex code. You could use this tool to help you:_ https://htmlcolorcodes.com/color-picker/

_Note: There should NOT be a table of contents on the cover page. It should look like a cover._

\newpage
# Executive summary

_Guidelines for the executive summary:_

* _No more than two pages_
* _Language is appropriate for a non-technical audience_
* _Bullet points are used where appropriate_
*	_A small number of key visualizations and/or tables are included_
*	_All research questions are addressed_

```{r, echo = FALSE}
cust_dev_info %>%
  ggplot(aes(x = income)) +
  geom_histogram() +
  facet_wrap(~is_new, 
             nrow = 2,
             labeller = labeller(is_new = c("1" = "New Customers", "0" = "Traditional Customers"))) +
  ggtitle("The Distribution of Median Income of the Sampled Customers") +
  xlab("Median Income") +
  theme_minimal()
```

```{r, echo = FALSE}
cust_dev_info %>%
  ggplot(aes(x = age)) +
  geom_histogram() +
  facet_wrap(~is_new, 
             nrow = 2,
             labeller = labeller(is_new = c("1" = "New Customers", "0" = "Traditional Customers"))) +
  ggtitle("The Distribution of Age of the Sampled Customers") +
  xlab("Age") +
  theme_minimal()
```

```{r, echo = FALSE}
cust_dev_info %>%
  ggplot(aes(x = pronouns)) +
  geom_bar() +
  facet_wrap(~is_new,
             nrow = 1,
             labeller = labeller(is_new = c("1" = "New Customers", "0" = "Traditional Customers"))) +
  ggtitle("The Frequencies of Different Pronouns Among the Sampled Customers") +
  xlab("Pronouns") +
  theme_minimal()
```


```{r performance_scatterplot, echo=FALSE, fig.cap="Scatterplots showing the relationship between duration of sleep session and number of flags for each emoji modifier."}
cust_sleep_complete %>%
  ggplot() +
  aes(x=duration, y=flags) +
  facet_wrap(~emoji_modifier) +
  geom_point() +
  xlab("Duration of Sleep (in minutes)") +
  ylab("Number of flags") +
  ggtitle("Distribution of sleep quality") #+
  #geom_smooth(method=lm)

  # Adding geom_smooth seems yikes
```

```{r performance_histogram, echo=FALSE, fig.cap="Histograms showing the distribution of the number of errors that occur in each sleep session."}
cust_sleep_complete %>%
  ggplot() +
  aes(x=flags) +
  facet_wrap(~emoji_modifier) +
  geom_histogram() +
  xlab("Number of flags") +
  ggtitle("Distribution of flags per sleep session")
```


## Limitations

-  The UofTears team did not have direct access to customer information such as income. Instead, customer income was extrapolated using the median income for their area via postal code.

-  Median income data used to estimate customer income came from the 2016 Canadian census and hence, does not perfectly align with customer income at time of product purchase.

<!-- _The [module 4 writing prompt](https://sta303-bolton.github.io/sta303-w22-courseguide/knowledge-basket-writing-and-peer-feedback.html#module-4-writing-task) provides some tips and information about writing executive summaries._ -->


\newpage
# Technical report
_This part of the report is much more comprehensive than the executive summary. The audience is statistics/data-minded people, but you should NOT include code or unformatted R output here._


## Introduction
<!-- _Provide a brief introduction to your report and outline what the report will cover. This section is valuable for setting scope and expectations. _ -->

This report provides customer and product analytics on MINGAR's fitness tracking wearable devices with the goal of delivering insights for better product strategizing. To better grasp the customer market of MINGAR's new affordable lines- 'Active' and 'Advance', the UofTears team details demographic characteristics of new customers that these products have attracted thus far- with a particular focus on the targeted lower-income customer segment. Additionally, this report discusses the discrepancy in product performance for customer of diverse races and highlights underlying issues that this presents. The analysis was conducted with respect to ethical concerns and a summary of UofTear's ethical code of conduct is included in the report.


### Research questions
<!-- _Use bullet points to to describe the research questions you are going to address. Write in full sentences._ -->

-  What are the demographic characteristics associated with customers of the new affordable product lines, "Active" and Advance" vs. customers of previous fitness wearable lines? This question aims to investigate whether the affordable product lines managed to successfully attract new customers of the lower-income target market.

- Are there unusual discrepancies in the quality of the data measured by MINGAR fitness wearables for customers of different races (specifically, those with darker skin tones) and differing amounts of sleep?


## Informative title for section addressing research question 1

_For each research question, you will want to briefly describe any data manipulation, show some exploratory plots/summary tables, report on any methods you use (i.e. models you fit) and the conclusions you draw from these_

For research question 1, we used the cancensus API to retrieve 2016 median incomes for each census subdivision (defined by its unique CSDuid). Next, we downloaded 2016 Census Canada Postal Code Conversion Files from the University of Toronto portal- which indicates the CSDuid for various postcodes. Joining these datasets, we were able to determine median income for each postal code. After that, we joined this newly joined dataset with our customer data on postcode to evaluate an estimate of our customers' incomes. Note that there are customers with more than 1 postcode (and hence, are matched with more than 1 income). For such customers, we will assigned them the mean of the multiple incomes. Moreover, we add a new variable "age" to our customer data to inform us of the customer's current age. We now merge this customer information data with cust_dev on cust_id. This allows us to get information on customers and the specific ID of their device. Now, we merge this dataset with our device dataset on dev_id to retrieve information on each customer's device. Finally, we select the relevant variables such that our customer's sensitive data are not made public in our report.


As a final data cleaning step, we create a new binary variable in the dataset that takes value 1 if a customer is considered "new" (i.e. is a buyer of our line of "Active" or "Advance" products) and 0 otherwise. This will allow us to build a model that predicts if, given some information about a customer, this customer belongs to the camp of "new" customers or if they belong to the camp of "traditional" customers, which will help us answer the question of who our new customers are and how they differ from those we consider to be our more "traditional" customers.

To start with some exploratory data analysis, we can examine the distribution of median incomes among the customers from whom we have collected data:

```{r, echo = FALSE}
cust_dev_info %>%
  ggplot(aes(x = income)) +
  geom_boxplot() +
  facet_wrap(~is_new, 
             nrow = 2,
             labeller = labeller(is_new = c("1" = "New Customers", "0" = "Traditional Customers"))) +
  ggtitle("The Distribution of Median Income of the Sampled Customers") +
  xlab("Median Income") +
  theme_minimal()
```

From the above boxplots, we can see first that for both traditional and new customers, the distribution of median incomes appears to be skewed to the right with a lot of outliers on the right tail, which is expected as income distributions tend to skew to the right in most settings. Another similarity between the two types of customers is that the median of the median income for both groups is around the same as seen by the placement of the middle bars in the boxplots above. However, one major contrast between the two types of customers is that the interquartile range of the median income for new customers appears to be narrower than that of the traditional customers. All of this can be summarized to mean that although the two groups of customers have similar median incomes, the new customers may have slightly less variation in median income as seen by the narrower interquartile range. This therefore means that the variable of median income could possibly play a role in separating customers belonging to the new and traditional camps.

Next, we can also look at the distribution of the ages of these customers:

```{r, echo = FALSE}
cust_dev_info %>%
  ggplot(aes(x = age)) +
  geom_boxplot() +
  facet_wrap(~is_new, 
             nrow = 2,
             labeller = labeller(is_new = c("1" = "New Customers", "0" = "Traditional Customers"))) +
  ggtitle("The Distribution of Age of the Sampled Customers") +
  xlab("Age") +
  theme_minimal()
```

From the above boxplots, we can see that for both traditional and new customers, the distribution of ages appears to be roughly skewed to the right and the median and spread of the ages for both groups is around the same as seen by the placement of the middle bars in the box. The only major difference between the distributions of the two groups is that ages considered to be outliers for traditional customers are not considered outliers for new customers, which suggests that the frequency of ages for traditional customers gradually levels off as age increases while the frequency of older ages for new customers suddenly drops off at a certain point, which is something we can't see on a boxplot. All of this can be summarized to mean that most of the features of the distributions of ages for both groups, such as the median and the skew, are the same, and therefore, we must be wary of deciding whether to use age as a predictor for determining whether a customer belongs to the traditional or the new group given this similarity.

Finally, we can examine the frequencies of the different pronouns used by these customers:

```{r, echo = FALSE}
cust_dev_info %>%
  ggplot(aes(x = pronouns)) +
  geom_bar() +
  facet_wrap(~is_new,
             nrow = 1,
             labeller = labeller(is_new = c("1" = "New Customers", "0" = "Traditional Customers"))) +
  ggtitle("The Frequencies of Different Pronouns Among the Sampled Customers") +
  xlab("Pronouns") +
  theme_minimal()
```

From the above barplots, we can see that for both traditional and new customers, the pronouns of "she/her" are used by the most customers, followed by "he/him" and "they/them". We can also see that the bars in the barplot corresponding to the new customers are taller than those in the other barplot, but that is to be expected as we know that there are 8476 customers belonging to the traditional camp and 10569 belonging to the new camp. Due to this, we must also be wary of deciding whether to use pronouns as a predictor for determining whether a customer belongs to the traditional or the new group, given how similar the frequencies of pronouns are across both groups.

Before building preliminary models, recall that as we are trying to gain insight as to what who tends to buy our "Active" and "Advance" line products and how they differ from our traditional customers who buy other lines, we know that the colour of the emoji that customers use has no direct or quantifiable (but still some) impact on whether they belong to the new or traditional camp, which is why we will include this as a random effect.

Now, we have the tools to build our preliminary models. Since the response is binary and we have a random effect, we must use a generalized linear mixed model (GLMM) for this data. We start by fitting a GLMM with all of the potential predictors that we have so far, including pronouns, median income, and age. Then, we create an auxiliary model that doesn't include pronouns as a predictor and another that doesn't include age as a predictor, since in the previous exploratory data analysis we could not determine whether these would be good predictors just based on eyeballing the boxplots. 

```{r, echo = FALSE, include = FALSE}
full_mod <- lme4::glmer(is_new ~ pronouns + scales::rescale(age) + scales::rescale(income) + (1 | emoji_modifier), data = cust_dev_info, family = 'binomial')
no_age <- lme4::glmer(is_new ~ pronouns + scales::rescale(income) + (1 | emoji_modifier), data = cust_dev_info, family = 'binomial')
no_pronouns <- lme4::glmer(is_new ~ scales::rescale(income) + scales::rescale(age) + (1 | emoji_modifier), data = cust_dev_info, family = 'binomial')

lmtest::lrtest(no_age, full_mod)
lmtest::lrtest(no_pronouns, full_mod)
```

By running likelihood ratio tests between the model containing all the predictors so far and the two auxiliary models, we conclude that while a model without age as a predictor will NOT explain the data as well as the model containing all the predictors, a model without pronouns as a predictor WILL explain the data as well as the model containing all the predictors. Thus, we conclude that pronouns can be discarded as a predictor in our final model.

```{r, echo = FALSE, include = FALSE}
finalmod <- lme4::glmer(is_new ~ scales::rescale(age) + scales::rescale(income) + (1 | emoji_modifier), data = cust_dev_info, family = 'binomial')
```

After building this final model, consider the following results:

```{r, echo = FALSE, cache = TRUE, include = FALSE}
ests <- format(round(exp(summary(finalmod)$coeff)[,1], 2), nsmall = 2)
confint <- confint(finalmod)
cis <- format(round(exp(confint),2)[-1,], nsmall = 2)
cis_pretty <- str_c("(", trimws(cis[,1]), ", ", cis[,2], ")")
```


```{r, echo = FALSE}

my_pretty_table <- cbind(ests, cis_pretty)
rownames_for_table <- c("Baseline odds", "Rescaled Age", "Rescaled Median Income")
colnames_for_table <- c("Estimate", "95% CI")
rownames(my_pretty_table) <- rownames_for_table
colnames(my_pretty_table) <- colnames_for_table

my_pretty_table %>%
  knitr::kable(caption = "Estimates of Odds Ratios and Corresponding 95 Percent Confidence Intervals")

```

First, note that we were forced to rescale age and median income in order to allow R to properly build the model. These variables were rescaled with the following formulae: 

$$\text{age}_{\text{rescaled}} = \frac{\text{age}_\text{raw} - \min(\text{age})}{\max(\text{age}) - \min(\text{age})}$$

$$\text{income}_{\text{rescaled}} = \frac{\text{income}_\text{raw} - \min(\text{income})}{\max(\text{income}) - \min(\text{income})}$$

where $\text{age}_\text{raw}$ and $\text{income}_\text{raw}$ correspond to the original, "raw" age or median income value that is to be rescaled, $\min(\text{age}), \min(\text{income}), \max(\text{age}),$ and $\max(\text{income})$ correspond to the minimum and maximum age and median income values among all customers in the dataset, and $\text{age}_{\text{rescaled}}$ and $\text{income}_{\text{rescaled}}$ correspond to the resulting rescaled age and median income value.

In the table, we can first see that the estimate of the baseline odds ratio is 1.93, which means that when both rescaled age and rescaled median income are 0, the odds of a customer belonging to the new camp is 1.93:1. Since a rescaled age of 0 and a rescaled median income of 0 correspond to the age of `r toString(min(cust_dev_info$age))` and the median income of `r toString(min(cust_dev_info$income))` respectively, we can say that the odds ratio of a customer belonging to the new camp is 1.93:1 when that customer is `r toString(min(cust_dev_info$age))` years old and lives in a region where the median income is `r toString(min(cust_dev_info$income))`. 

In the next row in the table, we have that the estimate of the odds ratio corresponding to the rescaled age is 1.46. This means that for every unit increase in rescaled age, the odds of a customer belonging to the new camp increase by about 46%. By definition, we have that a unit increase in rescaled age corresponds to a $\frac{1}{\max(\text{age}) - \min(\text{age})}$ increase in raw, unscaled age, so we conclude that for every approximately `r toString(1 / (max(cust_dev_info$age) - min(cust_dev_info$age)))` increase in a customer's age (this is approximately `r toString(365 / (max(cust_dev_info$age) - min(cust_dev_info$age)))` days), the odds of that customer belonging to the new camp increases by about 46%.

In the last row of the table, we have that the estimate of the odds ratio corresponding to the rescaled median income is 0.04, which means that for every unit increase in rescaled median income, the odds of a customer belonging to the new camp decreases by about 96%. Using the same logic as previously, we have that a unit increase in rescaled median income corresponds to a $\frac{1}{\max(\text{income}) - \min(\text{income})}$ increase in raw, unscaled median income, so we conclude that for every approximately `r toString(1 / (max(cust_dev_info$income) - min(cust_dev_info$income)))` increase in a customer's median income, the odds of that customer belonging to the new camp decreases by about 96%.

These estimates of the odds ratios corresponding to each of the variables in the model tell us that the youngest and lowest income customers have almost 2 to 1 odds of buying our newer and more affordable Active and Advance line products, and this trend is made even more clear by the fact that by even the smallest of increases in median income, the odds of a customer purchasing a product from one of these lines goes down by a staggering 96%. This allows us to conclude that among our lower income customers, our Active and Advance line products have indeed been able to attract considerable attention, and that our new customers mainly reside in regions of lower median income.

## Informative title for section addressing a research question 2

To address research question 2, we first retrieved device data scraped from the Fitness Tracker info hub [(which can be found here)](https://fitnesstrackerinfohub.netlify.app/), which gave us information on the device's name, line, retail price, and features. All data was scraped after confirming that we have permission from the website to do so. We also added a few potentially helpful variables to this dataset, including device retail price category and age based on its release date. Using the client provided data on device, we joined the two datasets to determine the device information corresponding to each device ID. From this, we selected only the devices that can track sleep, as sleep score is our main variable of interest. We then join this dataset with sleep data for each customer to match each sleep session to the associated device. From this, we selected only variables related to the investigation to protect customer privacy. We also dropped sessions with missing values for sex, pronouns, and/or postcode because there were not a lot to represent a significant trend, and they are not the predictors we wish to focus on for this question. The emoji_modifier unicodes were also converted to more interprettable labels.

With the data that we had, the only way to measure the quality of the data for a given sleep session was to measure the number of flags that was raised in the session. Furthermore, as we do not directly collect data on race or ethnicity, we were forced to use a proxy variable--using emoji-modifiers to predict each customer's skin tone. The following figure depicts the distribution in the duration of sleep sessions with differing number of flags raised for people with different emoji-modifiers. From the figure, note that we can see that when we are given the emoji-modifier of a customer, the relationship between the duration of sleep and the number of flags raised is roughly linear and homoscedastic, so we decided to fit a linear mixed model. The reason why we avoided generalized additive models is because we seeked to maximize interpretability, as we needed to explain our model to our employers.

```{r performance_interaction_or_not, echo=FALSE, eval=FALSE}
# Model with interaction included
device_performance_model_1 <- lm(flags ~ duration*emoji_modifier, 
                                 data=cust_sleep_complete)
# Model without included
device_performance_model_2 <- lm(flags ~ duration + emoji_modifier,
                                 data=cust_sleep_complete)

lmtest::lrtest(device_performance_model_1, device_performance_model_2)
# Interaction is needed
```

```{r age-or-sex, echo=FALSE, eval=FALSE}
# Model with Sex included
device_performance_model_1 <- lmer(flags ~ duration*emoji_modifier + (1|sex), 
                                 data=cust_sleep_complete)
# Model with Age included
device_performance_model_2 <- lmer(flags ~ duration*emoji_modifier + 
                                     (1|age), data=cust_sleep_complete)
# Model with both Age and Sex included
device_performance_model_3 <- lmer(flags ~ duration*emoji_modifier + (1|sex) + 
                                     (1|age), data=cust_sleep_complete)

lmtest::lrtest(device_performance_model_1, device_performance_model_3)
# Evidence that Age is not needed

lmtest::lrtest(device_performance_model_2, device_performance_model_3)
# Evidence that we do not need sex
```

```{r bat_life-or-line, echo=FALSE, eval=FALSE}
# Model with Sex included
device_performance_model_1 <- lmer(flags ~ duration*emoji_modifier + (1|line), 
                                 data=cust_sleep_complete)
# Model with Age included
device_performance_model_2 <- lmer(flags ~ duration*emoji_modifier + (1|bat_life), 
                                   data=cust_sleep_complete)
# Model with both Age and Sex included
device_performance_model_3 <- lmer(flags ~ duration*emoji_modifier + (1|line) + 
                                     (1|bat_life), data=cust_sleep_complete)

lmtest::lrtest(device_performance_model_1, device_performance_model_3)
# Evidence that bat_life is not needed

lmtest::lrtest(device_performance_model_2, device_performance_model_3)
# Evidence that line is not needed
```

As we are trying to understand if there are discrepancies between the performance of the device (i.e., quality of the data measured) for different sleep sessions, our predicted variable was the number of flags raised for a given sleep session. We were primarily interested in how the skin tone and the sleep quality affected these measurements, so we set the emoji-modifiers and the duration of a sleep session as the fixed effects. An ANOVA test led us to include the interaction between these two variables in our model. This was our baseline model. After performing many likelihood ratio tests on models with and without various random effects (i.e., the customer's age and gender, as well as the line and battery life of the device), we decided to include another model with age as a random effect.

```{r performance_boxplot, echo=FALSE, fig.cap="Box-plots that show the distribution of the sleep quality for different number of flags and different emojis used.", fig.height=6.6}
# create a visualization
cust_sleep_complete %>%
  mutate(flags=as.factor(flags)) %>%
  ggplot() +
  aes(y=duration, x=flags) +
  facet_wrap(~emoji_modifier) +
  geom_boxplot() +
  ylab("Duration of Sleep (in minutes)") +
  xlab("Number of flags") +
  ggtitle("Distribution of sleep quality")+
  coord_flip()
```

\newpage

There were some very interesting findings from our final models, as well as from our boxplot. First, from the boxplot, we can clearly see that only customers that use the dark skin tone emoji-modifier have experienced a sleep session with more than 22 flags. Similarly, only customers with dark skin tone or medium-dark skin tone emoji-modifiers have experienced a sleep session with more than 13 flags.

On to our models. The most meaningful thing to look at are the slopes of the models, which are shown in the table below. The LM model is the linear model with duration and the emoji-modifier (and its interaction) while the LMM model is the linear mixed-model with age as another random effect.

```{r summary_performance_model, echo=FALSE, eval=FALSE}
summary(device_performance_model_fixed)
summary(device_performance_model_mixed)
```

```{r performance_table, echo=FALSE}
tibble(`Emoji Modifiers` = c("Default", 
                                 "Light Skin Tone", 
                                 "Medium-Light Skin Tone",
                                 "Medium Skin Tone", 
                                 "Medium-Dark Skin Tone", 
                                 "Dark Skin Tone"),
       `LM Model Increase` = 
         c(0.006494,
           0.003046,
           0.007467,
           0.011354,
           0.022366,
           0.035384),
       `LMM Model Increase` = 
         c(0.006487,
           0.003052,
           0.007457,
           0.011361,
           0.022352,
           0.035391)) %>% 
  knitr::kable(caption = "Average Increase in number of Flags for 1 more minute of sleep")
```

We can see that for both models, as we move from a lighter emoji skin tone modifier to a darker emoji skin tone modifier, the average increase in number of flags for 1 more minute of sleep, which strongly suggests that the device performs more poorly when used by someone with darker skin. This implies that the complaint that the MINGAR social media team is dealing with is indeed valid.

## Discussion

_In this section you will summarize your findings across all the research questions and discuss the strengths and limitations of your work. It doesn't have to be long, but keep in mind that often people will just skim the intro and the discussion of a document like this, so make sure it is useful as a semi-standalone section (doesn't have to be completely standalone like the executive summary)._

### Strengths and limitations

The UofTears team prides ourselves on interpretability of our models. Whenever possible, the team makes conscious effort to work with models that are human-understandable. In fact,  all finalized models in this report are easily interpretable. Interpretability is important as understanding the decisions an algorithm takes can help to identify underlying prejudice in the algorithm.

With that said, the UofTears team faced a few limitations during this analysis. In the first research question, the team did not have direct access to customer incomes data and was required to make assumptions on a customer's income based on their postal code. While this generalization allows for reasonable analysis, for a more accurate report on market demographics, the team would need direct customer information. With that said, the UofTears team acknowledges that income is sensitive data and collection of such information may cause user privacy concerns. Moreover, the median income data used in this analysis was attained in 2016. Hence, this number may not be entirely reflective of the customer's income at time of purchase.

With regards to the second research question, one limiting factor is the presence of missing values for user's emoji modifier, which signifies that they used the default skintone. The UofTears team is thus unable to determine the race/ethnicity of those users, which adds uncertainty and limits the conclusions we were able to make about the relationship between device flags and user race. Similarly, a certain choice of emoji skintone does not necessarily correspond to the user's actual racial identity.

- mention something about data distribution maybe?

\newpage
# Consultant information
## Consultant profiles

*Complete this section with a brief bio for each member of your group. If you are completing the project individually, you only need to complete one for yourself. In that case, change the title of this section to 'Consultant profile' instead. Examples below. This section is only marked for completeness, clarity and professionalism, not 'truth' so you can write it as if we're a few years in the future. Put your current degree in as completed and/or add your first choice grad school program, whatever you like. What skills related skills would you most like to highlight? What job title do you want?*

**Chloe Nguyen**. Chloe is a third-year Data Science and Computer Science student at the University of Toronto. She specializes in data science and machine learning. Chloe has experience working in project management and software development at Microsoft's Cloud and AI team- where she collaborated with internal and external stakeholders to create project plans, build prototypes and develop solutions. Chloe is an avid member of UofT's Computer Science community, having lead various student unions and clubs-such as President of Women in Computer Science, Treasurer of the Computer Science Student Union and Sponsorship Executive of Neurotech.

**Shih-Ting (Cindy) Huang**. Cindy is currently a third-year undergraduate studying Data Science at the University of Toronto. With a passion for improving user experience through machine learning, she actively seeks ways to implement different theoretical concepts in real life for business-oriented problems. Her skills in multidisciplinary fields, including data science, marketing, and linguistics, have enabled her to obtain a holistic perspective on multiple projects and devise creative solutions with a user-guided mindset.

**Warren Zhu**. Warren is a professional Data and Computer Scientist with over 10 years of experience. He was a former researcher at the University of Toronto, specializing in Multi-lingual Natural Language Processing. Having great understanding and experience with many Mathematical and Statistical concepts, he now serves as a consultant in various fields, including (but not limited to) marketing, health care and linguistics.

**Xiaotang (Jeffrey) Zhou**. Some bio stuff here.

## Code of ethical conduct

_This section should be fairly short, no more than half a page. Assume a general audience, much like your executive summary._

The UofTears team is committed to abiding by ethical guidelines for statistical practice when preparing and analyzing data. We promise to avoid disclosing confidential information without prior permission from our clients, such as data on their customers and devices. Moreover, we seek to make careful conclusions about the data and the investigative questions at hand. In this report, we have listed out all the assumptions we made when constructing the models as well as potential limitations to our research, fully informing the audience of the context surrounding our conclusions. Lastly, we hold responsibility to the society. The goal of this investigation was not only to determine if products could have harmful biases towards certain populations, but also assist the general public in understanding easily how we have obtained those insights.

1. Responsibility to Society: "strive to advance public knowledge and understanding of information...providing assistance in discrediting false or misleading info"
2. Responsibility to Employers and Clients: avoid disclosure of confidential information without prior written permission
3. Prevent use of misleading summary of the data and ensure to detail all assumptions and limitations relevant to the data

* _Make at least three relevant statements about your company's approach to ethical statistical consulting. These should be appropriately in line with professional conduct advice like the [Statistical Society of Canada Code of Conduct](https://ssc.ca/sites/default/files/data/Members/public/Accreditation/ethics_e.pdf) or the [Ethical Guidelines for Statistical Practice from the American Statistical Society](https://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx). For example, "the customer is always right" ISN'T the type of thing an ethical statistical consultant would include._
*	_Be very careful not to just copy and paste from these other documents! Put things in your own words._


\newpage
# References

_You don't need to cite course materials, but consider all the the places you got data from, as well as the packages used and R itself. These are all things you should consider citing. Likewise, you might use some external resources on the emoji skin tones/Fitzpatrick scale, etc._
Achim Zeileis, Torsten Hothorn (2002). Diagnostic Checking in Regression
  Relationships. R News 2(3), 7-10. URL https://CRAN.R-project.org/doc/Rnews/

Dmytro Perepolkin (2019). polite: Be Nice on the Web. R package version 0.1.1.
  https://CRAN.R-project.org/package=polite
  
Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear
  Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48.
  doi:10.18637/jss.v067.i01.

Fitness tracker info hub. (n.d.). Retrieved April 3, 2022, 
  from https://fitnesstrackerinfohub.netlify.app/. 

Hadley Wickham (2021). rvest: Easily Harvest (Scrape) Web Pages. R package
  version 1.0.2. https://CRAN.R-project.org/package=rvest
  
Postal code conversion file. (2016). Toronto. Retrieved April 3, 2022, 
  from https://mdl.library.utoronto.ca/collections/numeric-data/census-canada/postal-code-conversion-file. 

R Core Team (2021). R: A language and environment for statistical computing. R
  Foundation for Statistical Computing, Vienna, Austria. URL
  https://www.R-project.org/.

Unicode, Inc. (n.d.). Full Emoji Modifier Sequences, v14.0. Unicode, Inc. 
  Retrieved April 4, 2022, from 
  https://unicode.org/emoji/charts/full-emoji-modifiers.html. 

von Bergmann, J., &amp; Cervantes, A. (2022, February 9). Population Density by 
  CensusMapper. Census Mapper. map. Retrieved April 3, 2022, 
  from https://censusmapper.ca/. 

Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source
  Software, 4(43), 1686, https://doi.org/10.21105/joss.01686

\newpage
# Appendix

_These appendices should outline in more detail the steps taken to access the following datasets. They should NOT include code, but should briefly describe the steps and important considerations. I.e., show that you understand what needs to be considered when web scraping, protecting licensed data, etc._

## Web scraping industry data on fitness tracker devices

Data on fitness tracker devices was scraped from the Fitness tracker info hub. The UofTears team first consulted its scraping permissions and provided our user agent information to clarify our intentions with the obtained data. Only absolutely necessary data was saved from the webpage. Our team sought not to duplicate the dataset for this study and instead only variables relevant for this study.

## Accessing Census data on median household income

Median household income data was attained via the Canadian census API. The UofTears team created an account through CensusMapper, followed the proper guidelines of the API for retrievement and credited CensusMapper in our report. This is open data, available to the public. The use of this data complies with guidelines of the Statistics Canada Open Data Licence.

## Accessing postcode conversion files

Postal code conversion data was retrieved from Census Canada via the University of Toronto portal. The UofTears team comprises of University of Toronto students and hence, had the proper credentials to access the data. In downloading the dataset, the UofTears team has agreed to the license agreement. The source for this information has been acknowledged in this report.


__Final advice: KNIT EARLY AND OFTEN!__
